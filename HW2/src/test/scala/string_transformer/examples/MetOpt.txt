Для исследования метода градиентного спуска были взяты три квадратичные функции
▷ f1 (x, y) = x2 + 13y 2
▷ f2 (x, y) = 6x2 + 7y 2 − 1
▷ f3 (x, y) = 5x2 + y 2 − xy
имеющие числа обусловленности 13, 1.17 и 6.37 соответственно. В качестве начальной
точки выбрана (-15, 15). Параметр eps отвечает за погрешность. Для метода градиентного
спуска с постоянным шагом параметр learning rate - величина шага, был взят равным 0.06.
Ниже приведены данные о количестве итераций, необходимых для нахождения минимума
каждой из функций с заданной точностью eps для градиентного спуска с постоянным
шагом метода, а также график траекторий метода

Наилучшим образом сходится функция f2 , имеющая наименьшее число обусловленности.
Также для поиска минимума был к тем же функциям применен метод градиентного
спуска с использованием метода одномерного поиска; в качестве метода одномерного
поиска был взят метода золотого сечения. Как и в методе спуска с постоянным шагом
наилучший результат показывает функция, имеющая наименьшее число обусловленности.
Ниже приведены данные о количестве выполненых итераций методом до нахождения им
1

точки минимума с точностью eps.

В методе золотого сечения, помимо вычисления значений функции и ее градиента
непосредственно в процессе градиентного спуска, на каждой итерации градиентного спуска
производится вычисление нового значения шага спуска, занимающее O(log(1+√5)/2 (eps−1 ))
операций, кроме того на каждой итерации градиентного спуска рассматриваемый интервал уменьшается в пропорции золотого сечения, что и дает методу преимущество над
градиентным спуском с постоянным шагом.
Влияние выбора точки старта: для оценки влияния состовляющих абсциссы, ординаты,
положения относительно точки минимума и расстояния выбранной точки старта спуска
на число итераций каждого метода была рассмотрена работа методов, начинающаяся в
пяти различных точках: (−15; 15), (−1; 15), (−15; 1), (15, −15), (−750, 750).
Ниже приведены результаты работы методов для каждой из точек, а также графики
траекторий спуска.
1 (-15;15) - данная точка взята за образец

2

3

2 (-1;15)

4

При сокращении расстояния до точки минимума по оси Х работа градиентного
спуска улучшается для функций, состовляющая градиента которых по оси Х меньше,
5

чем по оси Y, и ухудшается для тех, в чьем градиенте доминирует Х-составляющая.
Наибольшее влияние подобное преобразование окажет на спуск, использующие метод
золотого сечения, потому как при поиске направления наискорейшего убывания для
функций, чей градиент наиболее выражен по Х, в случае сокращения расстояния
только по данной координате, метод начинает совершать много лишних итераций,
находя точки вдоль направления наискорейшего убывания функции, однако сильно
отстоящие по Х от прямой соединяющую текущую точку и точку минимума
3 (-15;1)

6

Ситуация аналогичная сокращению расстояния по оси абсцисс
4 (15, -15)

7

Не меняя расстояния до точки минимума, но изменив току начала обхода, мы меняем
направление подхода к минимуму, и это окажет влияние на работу метода золотого

8

сечения, если для f (χ) хотя бы одна из ее частных производных fχ′ i содержит
компоненты не только по χi , потому как они будут оказывать влияние выбранное
при одномерном поиске направление обхода.
5 (-750, 750)

9

При масштабировании осей сходиться должно быстрее, кажется, это эквивалентно изменению расстояния по какой-то из осей пропорционально k

10

Требования к отчету

11

